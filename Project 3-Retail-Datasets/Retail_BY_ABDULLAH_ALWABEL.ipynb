{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Artificial Intelligence Capstone Project on Retail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Task: Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge,ElasticNet,Lasso\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,accuracy_score,r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          2  2015-06-30   5735        568     1      1            0   \n",
       "1      2          2  2015-06-30   9863        877     1      1            0   \n",
       "2      3          2  2015-06-30  13261       1072     1      1            0   \n",
       "3      4          2  2015-06-30  13106       1488     1      1            0   \n",
       "4      5          2  2015-06-30   6635        645     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/AbiiinSW/Downloads/Project 3-Retail-Datasets/train_data.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1             0   \n",
       "1      2          5  2015-07-31   6064        625     1      1             0   \n",
       "2      3          5  2015-07-31   8314        821     1      1             0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1             0   \n",
       "4      5          5  2015-07-31   4822        559     1      1             0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val= pd.read_csv(\"/Users/AbiiinSW/Downloads/Project 3-Retail-Datasets/test_data_hidden.csv\")\n",
    "test_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo  StateHoliday  SchoolHoliday\n",
       "0      1          5  2015-07-31     1      1             0              1\n",
       "1      2          5  2015-07-31     1      1             0              1\n",
       "2      3          5  2015-07-31     1      1             0              1\n",
       "3      4          5  2015-07-31     1      1             0              1\n",
       "4      5          5  2015-07-31     1      1             0              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv(\"/Users/AbiiinSW/Downloads/Project 3-Retail-Datasets/test_data.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train.copy()\n",
    "test_val_1 = test_val.copy()\n",
    "test_1 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 982644 entries, 0 to 982643\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Store          982644 non-null  int64 \n",
      " 1   DayOfWeek      982644 non-null  int64 \n",
      " 2   Date           982644 non-null  object\n",
      " 3   Sales          982644 non-null  int64 \n",
      " 4   Customers      982644 non-null  int64 \n",
      " 5   Open           982644 non-null  int64 \n",
      " 6   Promo          982644 non-null  int64 \n",
      " 7   StateHoliday   982644 non-null  object\n",
      " 8   SchoolHoliday  982644 non-null  int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 67.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0\n",
       "DayOfWeek        0\n",
       "Date             0\n",
       "Sales            0\n",
       "Customers        0\n",
       "Open             0\n",
       "Promo            0\n",
       "StateHoliday     0\n",
       "SchoolHoliday    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0\n",
       "DayOfWeek        0\n",
       "Date             0\n",
       "Open             0\n",
       "Promo            0\n",
       "StateHoliday     0\n",
       "SchoolHoliday    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    141204\n",
       "1    140270\n",
       "4    140270\n",
       "5    140270\n",
       "6    140270\n",
       "7    140270\n",
       "3    140090\n",
       "Name: DayOfWeek, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.DayOfWeek.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    5575\n",
       "4    5575\n",
       "5    5575\n",
       "1    4460\n",
       "2    4460\n",
       "6    4460\n",
       "7    4460\n",
       "Name: DayOfWeek, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.DayOfWeek.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    814204\n",
       "0    168440\n",
       "Name: Open, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Open.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30188\n",
       "0     4377\n",
       "Name: Open, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Open.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    609059\n",
       "1    373585\n",
       "Name: Promo, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Promo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20070\n",
       "1    14495\n",
       "Name: Promo, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Promo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'a', 'b', 'c', 0], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.StateHoliday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34565\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.StateHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    813700\n",
       "1    168944\n",
       "Name: SchoolHoliday, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SchoolHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21788\n",
       "1    12777\n",
       "Name: SchoolHoliday, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.SchoolHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-06-30', '2015-06-29', '2015-06-28', '2015-06-27',\n",
       "       '2015-06-26', '2015-06-25', '2015-06-24', '2015-06-23',\n",
       "       '2015-06-22', '2015-06-21', '2015-06-20', '2015-06-19',\n",
       "       '2015-06-18', '2015-06-17', '2015-06-16', '2015-06-15',\n",
       "       '2015-06-14', '2015-06-13', '2015-06-12', '2015-06-11',\n",
       "       '2015-06-10', '2015-06-09', '2015-06-08', '2015-06-07',\n",
       "       '2015-06-06', '2015-06-05', '2015-06-04', '2015-06-03',\n",
       "       '2015-06-02', '2015-06-01', '2015-05-31', '2015-05-30',\n",
       "       '2015-05-29', '2015-05-28', '2015-05-27', '2015-05-26',\n",
       "       '2015-05-25', '2015-05-24', '2015-05-23', '2015-05-22',\n",
       "       '2015-05-21', '2015-05-20', '2015-05-19', '2015-05-18',\n",
       "       '2015-05-17', '2015-05-16', '2015-05-15', '2015-05-14',\n",
       "       '2015-05-13', '2015-05-12', '2015-05-11', '2015-05-10',\n",
       "       '2015-05-09', '2015-05-08', '2015-05-07', '2015-05-06',\n",
       "       '2015-05-05', '2015-05-04', '2015-05-03', '2015-05-02',\n",
       "       '2015-05-01', '2015-04-30', '2015-04-29', '2015-04-28',\n",
       "       '2015-04-27', '2015-04-26', '2015-04-25', '2015-04-24',\n",
       "       '2015-04-23', '2015-04-22', '2015-04-21', '2015-04-20',\n",
       "       '2015-04-19', '2015-04-18', '2015-04-17', '2015-04-16',\n",
       "       '2015-04-15', '2015-04-14', '2015-04-13', '2015-04-12',\n",
       "       '2015-04-11', '2015-04-10', '2015-04-09', '2015-04-08',\n",
       "       '2015-04-07', '2015-04-06', '2015-04-05', '2015-04-04',\n",
       "       '2015-04-03', '2015-04-02', '2015-04-01', '2015-03-31',\n",
       "       '2015-03-30', '2015-03-29', '2015-03-28', '2015-03-27',\n",
       "       '2015-03-26', '2015-03-25', '2015-03-24', '2015-03-23',\n",
       "       '2015-03-22', '2015-03-21', '2015-03-20', '2015-03-19',\n",
       "       '2015-03-18', '2015-03-17', '2015-03-16', '2015-03-15',\n",
       "       '2015-03-14', '2015-03-13', '2015-03-12', '2015-03-11',\n",
       "       '2015-03-10', '2015-03-09', '2015-03-08', '2015-03-07',\n",
       "       '2015-03-06', '2015-03-05', '2015-03-04', '2015-03-03',\n",
       "       '2015-03-02', '2015-03-01', '2015-02-28', '2015-02-27',\n",
       "       '2015-02-26', '2015-02-25', '2015-02-24', '2015-02-23',\n",
       "       '2015-02-22', '2015-02-21', '2015-02-20', '2015-02-19',\n",
       "       '2015-02-18', '2015-02-17', '2015-02-16', '2015-02-15',\n",
       "       '2015-02-14', '2015-02-13', '2015-02-12', '2015-02-11',\n",
       "       '2015-02-10', '2015-02-09', '2015-02-08', '2015-02-07',\n",
       "       '2015-02-06', '2015-02-05', '2015-02-04', '2015-02-03',\n",
       "       '2015-02-02', '2015-02-01', '2015-01-31', '2015-01-30',\n",
       "       '2015-01-29', '2015-01-28', '2015-01-27', '2015-01-26',\n",
       "       '2015-01-25', '2015-01-24', '2015-01-23', '2015-01-22',\n",
       "       '2015-01-21', '2015-01-20', '2015-01-19', '2015-01-18',\n",
       "       '2015-01-17', '2015-01-16', '2015-01-15', '2015-01-14',\n",
       "       '2015-01-13', '2015-01-12', '2015-01-11', '2015-01-10',\n",
       "       '2015-01-09', '2015-01-08', '2015-01-07', '2015-01-06',\n",
       "       '2015-01-05', '2015-01-04', '2015-01-03', '2015-01-02',\n",
       "       '2015-01-01', '2014-12-31', '2014-12-30', '2014-12-29',\n",
       "       '2014-12-28', '2014-12-27', '2014-12-26', '2014-12-25',\n",
       "       '2014-12-24', '2014-12-23', '2014-12-22', '2014-12-21',\n",
       "       '2014-12-20', '2014-12-19', '2014-12-18', '2014-12-17',\n",
       "       '2014-12-16', '2014-12-15', '2014-12-14', '2014-12-13',\n",
       "       '2014-12-12', '2014-12-11', '2014-12-10', '2014-12-09',\n",
       "       '2014-12-08', '2014-12-07', '2014-12-06', '2014-12-05',\n",
       "       '2014-12-04', '2014-12-03', '2014-12-02', '2014-12-01',\n",
       "       '2014-11-30', '2014-11-29', '2014-11-28', '2014-11-27',\n",
       "       '2014-11-26', '2014-11-25', '2014-11-24', '2014-11-23',\n",
       "       '2014-11-22', '2014-11-21', '2014-11-20', '2014-11-19',\n",
       "       '2014-11-18', '2014-11-17', '2014-11-16', '2014-11-15',\n",
       "       '2014-11-14', '2014-11-13', '2014-11-12', '2014-11-11',\n",
       "       '2014-11-10', '2014-11-09', '2014-11-08', '2014-11-07',\n",
       "       '2014-11-06', '2014-11-05', '2014-11-04', '2014-11-03',\n",
       "       '2014-11-02', '2014-11-01', '2014-10-31', '2014-10-30',\n",
       "       '2014-10-29', '2014-10-28', '2014-10-27', '2014-10-26',\n",
       "       '2014-10-25', '2014-10-24', '2014-10-23', '2014-10-22',\n",
       "       '2014-10-21', '2014-10-20', '2014-10-19', '2014-10-18',\n",
       "       '2014-10-17', '2014-10-16', '2014-10-15', '2014-10-14',\n",
       "       '2014-10-13', '2014-10-12', '2014-10-11', '2014-10-10',\n",
       "       '2014-10-09', '2014-10-08', '2014-10-07', '2014-10-06',\n",
       "       '2014-10-05', '2014-10-04', '2014-10-03', '2014-10-02',\n",
       "       '2014-10-01', '2014-09-30', '2014-09-29', '2014-09-28',\n",
       "       '2014-09-27', '2014-09-26', '2014-09-25', '2014-09-24',\n",
       "       '2014-09-23', '2014-09-22', '2014-09-21', '2014-09-20',\n",
       "       '2014-09-19', '2014-09-18', '2014-09-17', '2014-09-16',\n",
       "       '2014-09-15', '2014-09-14', '2014-09-13', '2014-09-12',\n",
       "       '2014-09-11', '2014-09-10', '2014-09-09', '2014-09-08',\n",
       "       '2014-09-07', '2014-09-06', '2014-09-05', '2014-09-04',\n",
       "       '2014-09-03', '2014-09-02', '2014-09-01', '2014-08-31',\n",
       "       '2014-08-30', '2014-08-29', '2014-08-28', '2014-08-27',\n",
       "       '2014-08-26', '2014-08-25', '2014-08-24', '2014-08-23',\n",
       "       '2014-08-22', '2014-08-21', '2014-08-20', '2014-08-19',\n",
       "       '2014-08-18', '2014-08-17', '2014-08-16', '2014-08-15',\n",
       "       '2014-08-14', '2014-08-13', '2014-08-12', '2014-08-11',\n",
       "       '2014-08-10', '2014-08-09', '2014-08-08', '2014-08-07',\n",
       "       '2014-08-06', '2014-08-05', '2014-08-04', '2014-08-03',\n",
       "       '2014-08-02', '2014-08-01', '2014-07-31', '2014-07-30',\n",
       "       '2014-07-29', '2014-07-28', '2014-07-27', '2014-07-26',\n",
       "       '2014-07-25', '2014-07-24', '2014-07-23', '2014-07-22',\n",
       "       '2014-07-21', '2014-07-20', '2014-07-19', '2014-07-18',\n",
       "       '2014-07-17', '2014-07-16', '2014-07-15', '2014-07-14',\n",
       "       '2014-07-13', '2014-07-12', '2014-07-11', '2014-07-10',\n",
       "       '2014-07-09', '2014-07-08', '2014-07-07', '2014-07-06',\n",
       "       '2014-07-05', '2014-07-04', '2014-07-03', '2014-07-02',\n",
       "       '2014-07-01', '2014-06-30', '2014-06-29', '2014-06-28',\n",
       "       '2014-06-27', '2014-06-26', '2014-06-25', '2014-06-24',\n",
       "       '2014-06-23', '2014-06-22', '2014-06-21', '2014-06-20',\n",
       "       '2014-06-19', '2014-06-18', '2014-06-17', '2014-06-16',\n",
       "       '2014-06-15', '2014-06-14', '2014-06-13', '2014-06-12',\n",
       "       '2014-06-11', '2014-06-10', '2014-06-09', '2014-06-08',\n",
       "       '2014-06-07', '2014-06-06', '2014-06-05', '2014-06-04',\n",
       "       '2014-06-03', '2014-06-02', '2014-06-01', '2014-05-31',\n",
       "       '2014-05-30', '2014-05-29', '2014-05-28', '2014-05-27',\n",
       "       '2014-05-26', '2014-05-25', '2014-05-24', '2014-05-23',\n",
       "       '2014-05-22', '2014-05-21', '2014-05-20', '2014-05-19',\n",
       "       '2014-05-18', '2014-05-17', '2014-05-16', '2014-05-15',\n",
       "       '2014-05-14', '2014-05-13', '2014-05-12', '2014-05-11',\n",
       "       '2014-05-10', '2014-05-09', '2014-05-08', '2014-05-07',\n",
       "       '2014-05-06', '2014-05-05', '2014-05-04', '2014-05-03',\n",
       "       '2014-05-02', '2014-05-01', '2014-04-30', '2014-04-29',\n",
       "       '2014-04-28', '2014-04-27', '2014-04-26', '2014-04-25',\n",
       "       '2014-04-24', '2014-04-23', '2014-04-22', '2014-04-21',\n",
       "       '2014-04-20', '2014-04-19', '2014-04-18', '2014-04-17',\n",
       "       '2014-04-16', '2014-04-15', '2014-04-14', '2014-04-13',\n",
       "       '2014-04-12', '2014-04-11', '2014-04-10', '2014-04-09',\n",
       "       '2014-04-08', '2014-04-07', '2014-04-06', '2014-04-05',\n",
       "       '2014-04-04', '2014-04-03', '2014-04-02', '2014-04-01',\n",
       "       '2014-03-31', '2014-03-30', '2014-03-29', '2014-03-28',\n",
       "       '2014-03-27', '2014-03-26', '2014-03-25', '2014-03-24',\n",
       "       '2014-03-23', '2014-03-22', '2014-03-21', '2014-03-20',\n",
       "       '2014-03-19', '2014-03-18', '2014-03-17', '2014-03-16',\n",
       "       '2014-03-15', '2014-03-14', '2014-03-13', '2014-03-12',\n",
       "       '2014-03-11', '2014-03-10', '2014-03-09', '2014-03-08',\n",
       "       '2014-03-07', '2014-03-06', '2014-03-05', '2014-03-04',\n",
       "       '2014-03-03', '2014-03-02', '2014-03-01', '2014-02-28',\n",
       "       '2014-02-27', '2014-02-26', '2014-02-25', '2014-02-24',\n",
       "       '2014-02-23', '2014-02-22', '2014-02-21', '2014-02-20',\n",
       "       '2014-02-19', '2014-02-18', '2014-02-17', '2014-02-16',\n",
       "       '2014-02-15', '2014-02-14', '2014-02-13', '2014-02-12',\n",
       "       '2014-02-11', '2014-02-10', '2014-02-09', '2014-02-08',\n",
       "       '2014-02-07', '2014-02-06', '2014-02-05', '2014-02-04',\n",
       "       '2014-02-03', '2014-02-02', '2014-02-01', '2014-01-31',\n",
       "       '2014-01-30', '2014-01-29', '2014-01-28', '2014-01-27',\n",
       "       '2014-01-26', '2014-01-25', '2014-01-24', '2014-01-23',\n",
       "       '2014-01-22', '2014-01-21', '2014-01-20', '2014-01-19',\n",
       "       '2014-01-18', '2014-01-17', '2014-01-16', '2014-01-15',\n",
       "       '2014-01-14', '2014-01-13', '2014-01-12', '2014-01-11',\n",
       "       '2014-01-10', '2014-01-09', '2014-01-08', '2014-01-07',\n",
       "       '2014-01-06', '2014-01-05', '2014-01-04', '2014-01-03',\n",
       "       '2014-01-02', '2014-01-01', '2013-12-31', '2013-12-30',\n",
       "       '2013-12-29', '2013-12-28', '2013-12-27', '2013-12-26',\n",
       "       '2013-12-25', '2013-12-24', '2013-12-23', '2013-12-22',\n",
       "       '2013-12-21', '2013-12-20', '2013-12-19', '2013-12-18',\n",
       "       '2013-12-17', '2013-12-16', '2013-12-15', '2013-12-14',\n",
       "       '2013-12-13', '2013-12-12', '2013-12-11', '2013-12-10',\n",
       "       '2013-12-09', '2013-12-08', '2013-12-07', '2013-12-06',\n",
       "       '2013-12-05', '2013-12-04', '2013-12-03', '2013-12-02',\n",
       "       '2013-12-01', '2013-11-30', '2013-11-29', '2013-11-28',\n",
       "       '2013-11-27', '2013-11-26', '2013-11-25', '2013-11-24',\n",
       "       '2013-11-23', '2013-11-22', '2013-11-21', '2013-11-20',\n",
       "       '2013-11-19', '2013-11-18', '2013-11-17', '2013-11-16',\n",
       "       '2013-11-15', '2013-11-14', '2013-11-13', '2013-11-12',\n",
       "       '2013-11-11', '2013-11-10', '2013-11-09', '2013-11-08',\n",
       "       '2013-11-07', '2013-11-06', '2013-11-05', '2013-11-04',\n",
       "       '2013-11-03', '2013-11-02', '2013-11-01', '2013-10-31',\n",
       "       '2013-10-30', '2013-10-29', '2013-10-28', '2013-10-27',\n",
       "       '2013-10-26', '2013-10-25', '2013-10-24', '2013-10-23',\n",
       "       '2013-10-22', '2013-10-21', '2013-10-20', '2013-10-19',\n",
       "       '2013-10-18', '2013-10-17', '2013-10-16', '2013-10-15',\n",
       "       '2013-10-14', '2013-10-13', '2013-10-12', '2013-10-11',\n",
       "       '2013-10-10', '2013-10-09', '2013-10-08', '2013-10-07',\n",
       "       '2013-10-06', '2013-10-05', '2013-10-04', '2013-10-03',\n",
       "       '2013-10-02', '2013-10-01', '2013-09-30', '2013-09-29',\n",
       "       '2013-09-28', '2013-09-27', '2013-09-26', '2013-09-25',\n",
       "       '2013-09-24', '2013-09-23', '2013-09-22', '2013-09-21',\n",
       "       '2013-09-20', '2013-09-19', '2013-09-18', '2013-09-17',\n",
       "       '2013-09-16', '2013-09-15', '2013-09-14', '2013-09-13',\n",
       "       '2013-09-12', '2013-09-11', '2013-09-10', '2013-09-09',\n",
       "       '2013-09-08', '2013-09-07', '2013-09-06', '2013-09-05',\n",
       "       '2013-09-04', '2013-09-03', '2013-09-02', '2013-09-01',\n",
       "       '2013-08-31', '2013-08-30', '2013-08-29', '2013-08-28',\n",
       "       '2013-08-27', '2013-08-26', '2013-08-25', '2013-08-24',\n",
       "       '2013-08-23', '2013-08-22', '2013-08-21', '2013-08-20',\n",
       "       '2013-08-19', '2013-08-18', '2013-08-17', '2013-08-16',\n",
       "       '2013-08-15', '2013-08-14', '2013-08-13', '2013-08-12',\n",
       "       '2013-08-11', '2013-08-10', '2013-08-09', '2013-08-08',\n",
       "       '2013-08-07', '2013-08-06', '2013-08-05', '2013-08-04',\n",
       "       '2013-08-03', '2013-08-02', '2013-08-01', '2013-07-31',\n",
       "       '2013-07-30', '2013-07-29', '2013-07-28', '2013-07-27',\n",
       "       '2013-07-26', '2013-07-25', '2013-07-24', '2013-07-23',\n",
       "       '2013-07-22', '2013-07-21', '2013-07-20', '2013-07-19',\n",
       "       '2013-07-18', '2013-07-17', '2013-07-16', '2013-07-15',\n",
       "       '2013-07-14', '2013-07-13', '2013-07-12', '2013-07-11',\n",
       "       '2013-07-10', '2013-07-09', '2013-07-08', '2013-07-07',\n",
       "       '2013-07-06', '2013-07-05', '2013-07-04', '2013-07-03',\n",
       "       '2013-07-02', '2013-07-01', '2013-06-30', '2013-06-29',\n",
       "       '2013-06-28', '2013-06-27', '2013-06-26', '2013-06-25',\n",
       "       '2013-06-24', '2013-06-23', '2013-06-22', '2013-06-21',\n",
       "       '2013-06-20', '2013-06-19', '2013-06-18', '2013-06-17',\n",
       "       '2013-06-16', '2013-06-15', '2013-06-14', '2013-06-13',\n",
       "       '2013-06-12', '2013-06-11', '2013-06-10', '2013-06-09',\n",
       "       '2013-06-08', '2013-06-07', '2013-06-06', '2013-06-05',\n",
       "       '2013-06-04', '2013-06-03', '2013-06-02', '2013-06-01',\n",
       "       '2013-05-31', '2013-05-30', '2013-05-29', '2013-05-28',\n",
       "       '2013-05-27', '2013-05-26', '2013-05-25', '2013-05-24',\n",
       "       '2013-05-23', '2013-05-22', '2013-05-21', '2013-05-20',\n",
       "       '2013-05-19', '2013-05-18', '2013-05-17', '2013-05-16',\n",
       "       '2013-05-15', '2013-05-14', '2013-05-13', '2013-05-12',\n",
       "       '2013-05-11', '2013-05-10', '2013-05-09', '2013-05-08',\n",
       "       '2013-05-07', '2013-05-06', '2013-05-05', '2013-05-04',\n",
       "       '2013-05-03', '2013-05-02', '2013-05-01', '2013-04-30',\n",
       "       '2013-04-29', '2013-04-28', '2013-04-27', '2013-04-26',\n",
       "       '2013-04-25', '2013-04-24', '2013-04-23', '2013-04-22',\n",
       "       '2013-04-21', '2013-04-20', '2013-04-19', '2013-04-18',\n",
       "       '2013-04-17', '2013-04-16', '2013-04-15', '2013-04-14',\n",
       "       '2013-04-13', '2013-04-12', '2013-04-11', '2013-04-10',\n",
       "       '2013-04-09', '2013-04-08', '2013-04-07', '2013-04-06',\n",
       "       '2013-04-05', '2013-04-04', '2013-04-03', '2013-04-02',\n",
       "       '2013-04-01', '2013-03-31', '2013-03-30', '2013-03-29',\n",
       "       '2013-03-28', '2013-03-27', '2013-03-26', '2013-03-25',\n",
       "       '2013-03-24', '2013-03-23', '2013-03-22', '2013-03-21',\n",
       "       '2013-03-20', '2013-03-19', '2013-03-18', '2013-03-17',\n",
       "       '2013-03-16', '2013-03-15', '2013-03-14', '2013-03-13',\n",
       "       '2013-03-12', '2013-03-11', '2013-03-10', '2013-03-09',\n",
       "       '2013-03-08', '2013-03-07', '2013-03-06', '2013-03-05',\n",
       "       '2013-03-04', '2013-03-03', '2013-03-02', '2013-03-01',\n",
       "       '2013-02-28', '2013-02-27', '2013-02-26', '2013-02-25',\n",
       "       '2013-02-24', '2013-02-23', '2013-02-22', '2013-02-21',\n",
       "       '2013-02-20', '2013-02-19', '2013-02-18', '2013-02-17',\n",
       "       '2013-02-16', '2013-02-15', '2013-02-14', '2013-02-13',\n",
       "       '2013-02-12', '2013-02-11', '2013-02-10', '2013-02-09',\n",
       "       '2013-02-08', '2013-02-07', '2013-02-06', '2013-02-05',\n",
       "       '2013-02-04', '2013-02-03', '2013-02-02', '2013-02-01',\n",
       "       '2013-01-31', '2013-01-30', '2013-01-29', '2013-01-28',\n",
       "       '2013-01-27', '2013-01-26', '2013-01-25', '2013-01-24',\n",
       "       '2013-01-23', '2013-01-22', '2013-01-21', '2013-01-20',\n",
       "       '2013-01-19', '2013-01-18', '2013-01-17', '2013-01-16',\n",
       "       '2013-01-15', '2013-01-14', '2013-01-13', '2013-01-12',\n",
       "       '2013-01-11', '2013-01-10', '2013-01-09', '2013-01-08',\n",
       "       '2013-01-07', '2013-01-06', '2013-01-05', '2013-01-04',\n",
       "       '2013-01-03', '2013-01-02', '2013-01-01'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-05-20    1115\n",
       "2013-07-28    1115\n",
       "2013-01-21    1115\n",
       "2013-06-26    1115\n",
       "2014-01-02    1115\n",
       "              ... \n",
       "2014-12-30     935\n",
       "2014-07-30     935\n",
       "2014-09-01     935\n",
       "2014-10-05     935\n",
       "2014-07-07     935\n",
       "Name: Date, Length: 911, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017209, 9)\n",
      "(1051774, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date    Sales  Customers  Open  Promo  \\\n",
       "0      1          2  2015-06-30   5735.0      568.0     1      1   \n",
       "1      2          2  2015-06-30   9863.0      877.0     1      1   \n",
       "2      3          2  2015-06-30  13261.0     1072.0     1      1   \n",
       "3      4          2  2015-06-30  13106.0     1488.0     1      1   \n",
       "4      5          2  2015-06-30   6635.0      645.0     1      1   \n",
       "\n",
       "   StateHoliday  SchoolHoliday  year  month  day  \n",
       "0             0              0     2      6   30  \n",
       "1             0              0     2      6   30  \n",
       "2             0              1     2      6   30  \n",
       "3             0              0     2      6   30  \n",
       "4             0              0     2      6   30  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val.sort_values(['Store'],inplace=True)\n",
    "test.sort_values(['Store'],inplace=True)\n",
    "combi = train.append(test_val , ignore_index=True)\n",
    "print(combi.shape)\n",
    "combi =combi.append(test , ignore_index=True)\n",
    "print(combi.shape)\n",
    "combi['year']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.year \n",
    "combi['month']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.month \n",
    "combi['day']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.day\n",
    "combi['year'] = combi.year.replace({2013 : 0, 2014 : 1 , 2015 : 2 })\n",
    "combi['StateHoliday'] = combi.StateHoliday.replace({'0' : 0, 'a' : 1 , 'b' : 2 ,'c' : 3})\n",
    "combi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "      <th>DayOfWeek_7</th>\n",
       "      <th>Open_1</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Sales  Customers  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  \\\n",
       "0  2015-06-30   5735.0      568.0            1            0            0   \n",
       "1  2015-06-30   9863.0      877.0            1            0            0   \n",
       "2  2015-06-30  13261.0     1072.0            1            0            0   \n",
       "3  2015-06-30  13106.0     1488.0            1            0            0   \n",
       "4  2015-06-30   6635.0      645.0            1            0            0   \n",
       "\n",
       "   DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  Open_1  ...  month_3  month_4  \\\n",
       "0            0            0            0       1  ...        0        0   \n",
       "1            0            0            0       1  ...        0        0   \n",
       "2            0            0            0       1  ...        0        0   \n",
       "3            0            0            0       1  ...        0        0   \n",
       "4            0            0            0       1  ...        0        0   \n",
       "\n",
       "   month_5  month_6  month_7  month_8  month_9  month_10  month_11  month_12  \n",
       "0        0        1        0        0        0         0         0         0  \n",
       "1        0        1        0        0        0         0         0         0  \n",
       "2        0        1        0        0        0         0         0         0  \n",
       "3        0        1        0        0        0         0         0         0  \n",
       "4        0        1        0        0        0         0         0         0  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi1= pd.get_dummies(combi,columns=['DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', 'year','Store','day','month'],drop_first=True)\n",
    "# combi1=pd.read_csv('combi1.csv')\n",
    "# combi1.drop(['Unnamed: 0'],axis=True,inplace=True)\n",
    "combi1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "      <th>DayOfWeek_7</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date    Sales  Customers  DayOfWeek_2  DayOfWeek_3  \\\n",
       "0      1  2015-06-30   5735.0      568.0            1            0   \n",
       "1      2  2015-06-30   9863.0      877.0            1            0   \n",
       "2      3  2015-06-30  13261.0     1072.0            1            0   \n",
       "3      4  2015-06-30  13106.0     1488.0            1            0   \n",
       "4      5  2015-06-30   6635.0      645.0            1            0   \n",
       "\n",
       "   DayOfWeek_4  DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  ...  month_3  month_4  \\\n",
       "0            0            0            0            0  ...        0        0   \n",
       "1            0            0            0            0  ...        0        0   \n",
       "2            0            0            0            0  ...        0        0   \n",
       "3            0            0            0            0  ...        0        0   \n",
       "4            0            0            0            0  ...        0        0   \n",
       "\n",
       "   month_5  month_6  month_7  month_8  month_9  month_10  month_11  month_12  \n",
       "0        0        1        0        0        0         0         0         0  \n",
       "1        0        1        0        0        0         0         0         0  \n",
       "2        0        1        0        0        0         0         0         0  \n",
       "3        0        1        0        0        0         0         0         0  \n",
       "4        0        1        0        0        0         0         0         0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi2= pd.get_dummies(combi,columns=['DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', 'year','day','month'],drop_first=True)\n",
    "combi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((982644, 9), (34565, 9), (34565, 7))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test_val.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((982644, 1172), (34565, 1172), (34565, 1172))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = combi1.iloc[:982644].reset_index(drop=True)\n",
    "test_val1 = combi1.iloc[982644:1017209].reset_index(drop=True)\n",
    "test1 = combi1.iloc[1017209:].reset_index(drop=True)\n",
    "train1.shape,test_val1.shape,test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((982644, 59), (34565, 59), (34565, 59))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = combi2.iloc[:982644].reset_index(drop=True)\n",
    "test_val2 = combi2.iloc[982644:1017209].reset_index(drop=True)\n",
    "test2 = combi2.iloc[1017209:].reset_index(drop=True)\n",
    "train2.shape,test_val2.shape,test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0.005338\n",
       "DayOfWeek       -0.461249\n",
       "Sales            1.000000\n",
       "Customers        0.895700\n",
       "Open             0.679248\n",
       "Promo            0.451383\n",
       "SchoolHoliday    0.076141\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.541150</td>\n",
       "      <td>Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.773128</td>\n",
       "      <td>DayOfWeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.956526</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.190168</td>\n",
       "      <td>Customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.210847</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.154974</td>\n",
       "      <td>Promo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.207436</td>\n",
       "      <td>SchoolHoliday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF       features\n",
       "0   3.541150          Store\n",
       "1   2.773128      DayOfWeek\n",
       "2  21.956526          Sales\n",
       "3  15.190168      Customers\n",
       "4   8.210847           Open\n",
       "5   2.154974          Promo\n",
       "6   1.207436  SchoolHoliday"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "x=train._get_numeric_data()\n",
    "vif=pd.DataFrame()\n",
    "vif[\"VIF\"]=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
    "vif[\"features\"]=x.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with STORE as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train1['Sales']\n",
    "Y_val = test_val1['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1428.9181706826778\n",
      "MAE 1051.5557239043487\n",
      "train model score 0.8365645595889427\n",
      "test model score 0.8430035399815972\n"
     ]
    }
   ],
   "source": [
    "X_train = train1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "lr_1 = LinearRegression()\n",
    "lr_1.fit(X_train,Y_train)\n",
    "Y_pred1 = lr_1.predict(X_val)\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred1,Y_val))\n",
    "print('train model score',lr_1.score(X_train,Y_train))\n",
    "print('test model score',lr_1.score(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression without STORE as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 2520.0716734481693\n",
      "MAE 1731.704737951633\n",
      "train model score 0.5646267338030363\n",
      "test model score 0.5116840301951011\n"
     ]
    }
   ],
   "source": [
    "X_train1 = train2.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val1 = test_val2.drop(['Sales','Date','Customers'],axis=1).values\n",
    "lr_2 = LinearRegression()\n",
    "lr_2.fit(X_train1,Y_train)\n",
    "Y_pred2 = lr_2.predict(X_val1)\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred2,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred2,Y_val))\n",
    "print('train model score',lr_2.score(X_train1,Y_train))\n",
    "print('test model score',lr_2.score(X_val1,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression - Separate model for each STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 617791598632999.0\n",
      "MAE 14098079978199.238\n"
     ]
    }
   ],
   "source": [
    "Y_pred3=np.zeros(test_val.shape[0])\n",
    "\n",
    "train_store = train2.groupby(['Store'])\n",
    "test_store = test_val2.groupby(['Store'])\n",
    "\n",
    "for i in range(1,1116):\n",
    "    a = train_store.get_group(i)\n",
    "    b = test_store.get_group(i)\n",
    "    X_train = a.drop(['Sales','Date','Store','Customers'],axis=1).values\n",
    "    X_val = b.drop(['Sales','Date','Store','Customers'],axis=1).values\n",
    "    Y_train = a['Sales']\n",
    "    #Y_val = b['Sales']\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,Y_train)\n",
    "    pred = lr.predict(X_val)\n",
    "    i=0\n",
    "    for j in b.index:\n",
    "        Y_pred3[j]=pred[i]\n",
    "        i+=1\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred3,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred3,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the above 3 models we can conclude that the model perform better with 'Store' as feature.\n",
    "Also the average of all the separate model based on Store Id is the worst model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Ensemble Model of first and second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1786.5727235271445\n",
      "MAE 1295.536559435401\n"
     ]
    }
   ],
   "source": [
    "final_pred=(Y_pred1+Y_pred2)/2\n",
    "print('MSE',np.sqrt(mean_squared_error(final_pred,Y_val)))\n",
    "print('MAE',mean_absolute_error(final_pred,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Average Ensemble Model of first and second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1578.214817787205\n",
      "MAE 1163.7769636251792\n"
     ]
    }
   ],
   "source": [
    "final_pred=Y_pred1*0.7+Y_pred2*0.3\n",
    "print('MSE',np.sqrt(mean_squared_error(final_pred,Y_val)))\n",
    "print('MAE',mean_absolute_error(final_pred,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization of 1st Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [982644, 911]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-fad185460007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_val1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Customers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrr\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY_pred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m         _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X),\n\u001b[1;32m    541\u001b[0m                                                   self.solver)\n\u001b[0;32m--> 542\u001b[0;31m         X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    543\u001b[0m                                    \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [982644, 911]"
     ]
    }
   ],
   "source": [
    "X_train = train1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "rr =Ridge(alpha=10)\n",
    "rr.fit(X_train,Y_train)\n",
    "Y_pred1 = rr.predict(X_val)\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred1,Y_val))\n",
    "print('train model score',rr.score(X_train,Y_train))\n",
    "print('test model score',rr.score(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regualrization technique is not enhancing the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Task: Week 2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814204\n",
      "(848769, 9)\n",
      "(883334, 9)\n",
      "(814204, 9) (34565, 9) (34565, 7)\n",
      "(814204, 1172) (34565, 1172) (34565, 1172)\n",
      "(814204, 59) (34565, 59) (34565, 59)\n"
     ]
    }
   ],
   "source": [
    "train=train[train.Open==1]\n",
    "shape1=train.shape[0]\n",
    "print(train.shape[0])\n",
    "combi = train.append(test_val , ignore_index=True,sort=False)\n",
    "shape2=combi.shape[0]\n",
    "print(combi.shape)\n",
    "combi =combi.append(test , ignore_index=True,sort=False)\n",
    "print(combi.shape)\n",
    "combi['year']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.year \n",
    "combi['month']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.month \n",
    "combi['day']=pd.to_datetime(combi['Date'],format='%Y-%m-%d').dt.day\n",
    "combi['year'] = combi.year.replace({2013 : 0, 2014 : 1 , 2015 : 2 })\n",
    "combi['StateHoliday'] = combi.StateHoliday.replace({'0' : 0, 'a' : 1 , 'b' : 2 ,'c' : 3})\n",
    "#with Store Id as features\n",
    "combi1= pd.get_dummies(combi,columns=['DayOfWeek', 'Promo','StateHoliday', 'SchoolHoliday', 'year','Store','day','month'],drop_first=True)\n",
    "#without Store Id as features\n",
    "combi2= pd.get_dummies(combi,columns=['DayOfWeek', 'Promo','StateHoliday', 'SchoolHoliday', 'year','day','month'],drop_first=True)\n",
    "\n",
    "print(train.shape,test_val.shape,test.shape)\n",
    "\n",
    "train1 = combi1.iloc[:shape1].reset_index(drop=True)\n",
    "test_val1 = combi1.iloc[shape1:shape2].reset_index(drop=True)\n",
    "test1 = combi1.iloc[shape2:].reset_index(drop=True)\n",
    "print(train1.shape,test_val1.shape,test1.shape)\n",
    "\n",
    "train2 = combi2.iloc[:shape1].reset_index(drop=True)\n",
    "test_val2 = combi2.iloc[shape1:shape2].reset_index(drop=True)\n",
    "test2 = combi2.iloc[shape2:].reset_index(drop=True)\n",
    "print(train2.shape,test_val2.shape,test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train1['Sales']\n",
    "Y_val = test_val1['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 3519.2466804063965\n",
      "MAE 2207.5942264072805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,Y_train)\n",
    "pred1 = lr.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))\n",
    "\n",
    "# MSE 1428.9181706827264\n",
    "# MAE 1051.555723904386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 4372.392117586252\n",
      "MAE 3168.944605518081\n"
     ]
    }
   ],
   "source": [
    "X_train1 = train2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val1 = test_val2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train1,Y_train)\n",
    "pred2 = lr.predict(X_val1)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred2[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred2,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred2,Y_val))\n",
    "\n",
    "# MSE 2520.0716734481657\n",
    "# MAE 1731.704737951524"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1013.9379024007219\n",
      "MAE 669.8719998788438\n"
     ]
    }
   ],
   "source": [
    "pred3=np.zeros(test_val.shape[0])\n",
    "\n",
    "train_store = train2.groupby(['Store'])\n",
    "test_store = test_val2.groupby(['Store'])\n",
    "\n",
    "for i in range(1,1116):\n",
    "    a = train_store.get_group(i)\n",
    "    b = test_store.get_group(i)\n",
    "    X_train = a.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    X_val = b.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    Y_train = a['Sales']\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,Y_train)\n",
    "    pred = lr.predict(X_val)\n",
    "    i=0\n",
    "    ind=b[b['Open']==0].index\n",
    "    for j in b.index:\n",
    "        if(j in ind):\n",
    "            pred3[j]=0\n",
    "        else:\n",
    "            pred3[j]=pred[i]\n",
    "        i+=1\n",
    "print('MSE',np.sqrt(mean_squared_error(pred3,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred3,Y_val))\n",
    "\n",
    "# MSE 2886004774448802.0\n",
    "# MAE 65858982569725.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization of Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above model,we can see the performance has increased due to data cleaning except in 2nd model which remains almost same. In this case third model has outperformed which was earlier worst model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 930.9742188387742\n",
      "MAE 629.3727064444969\n"
     ]
    }
   ],
   "source": [
    "train_store = train2.groupby(['Store'])\n",
    "test_store = test_val2.groupby(['Store'])\n",
    "\n",
    "for i in range(1,1116):\n",
    "    a = train_store.get_group(i)\n",
    "    b = test_store.get_group(i)\n",
    "    X_train = a.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    X_val = b.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    Y_train = a['Sales']\n",
    "    lr = Ridge(alpha=20)\n",
    "    lr.fit(X_train,Y_train)\n",
    "    pred = lr.predict(X_val)\n",
    "    i=0\n",
    "    ind=b[b['Open']==0].index\n",
    "    for j in b.index:\n",
    "        if(j in ind):\n",
    "            pred3[j]=0\n",
    "        else:\n",
    "            pred3[j]=pred[i]\n",
    "        i+=1\n",
    "print('MSE',np.sqrt(mean_squared_error(pred3,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred3,Y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3rd model's performance is increasing with regularization \n",
    "\n",
    "model3:                 MSE 1014.9293535430203         MAE 670.5513943441184\n",
    "\n",
    "after reegularization:  MSE 930.9742188387742          MAE 629.3727064444969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [814204, 754]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-700b9ce8e192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[0;32m--> 304\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [814204, 754]"
     ]
    }
   ],
   "source": [
    "#With Store as Feature\n",
    "X_train = train1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=500,max_features='sqrt',max_depth=6,random_state=0,n_jobs=7)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Store as Feature\n",
    "X_train = train2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "clf = RandomForestRegressor(n_estimators=500,max_features='sqrt',max_depth=6,random_state=0,n_jobs=7)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate model for each Store\n",
    "pred3=np.zeros(test_val.shape[0])\n",
    "\n",
    "train_store = train2.groupby(['Store'])\n",
    "test_store = test_val2.groupby(['Store'])\n",
    "\n",
    "for i in range(1,1116):\n",
    "    a = train_store.get_group(i)\n",
    "    b = test_store.get_group(i)\n",
    "    X_train = a.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    X_val = b.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    Y_train = a['Sales']\n",
    "    clf = RandomForestRegressor(n_estimators=500,max_features='sqrt',max_depth=6,random_state=0,n_jobs=7)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    pred = clf.predict(X_val)\n",
    "    i=0\n",
    "    ind=b[b['Open']==0].index\n",
    "    for j in b.index:\n",
    "        if(j in ind):\n",
    "            pred3[j]=0\n",
    "        else:\n",
    "            pred3[j]=pred[i]\n",
    "        i+=1\n",
    "print('MSE',np.sqrt(mean_squared_error(pred3,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred3,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "pca = PCA().fit(X_train)\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()\n",
    "# Cumulative Variance explains\n",
    "# var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "# print(var1.shape)\n",
    "# print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "Y_train = train1['Sales']\n",
    "Y_val = test_val1['Sales']\n",
    "\n",
    "pca = PCA(n_components=50)  \n",
    "X_train = pca.fit_transform(X_train)  \n",
    "X_val= pca.transform(X_val) \n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=500,max_features='sqrt',max_depth=6,random_state=0,n_jobs=7)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Store as Feature\n",
    "X_train = train1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "\n",
    "clf = XGBRegressor(n_estimators=500, learning_rate=0.5,max_depth=6,random_state=0,n_jobs=-1)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Store as Feature\n",
    "X_train = train2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "X_val = test_val2.drop(['Sales','Date','Open','Customers'],axis=1).values\n",
    "clf = XGBRegressor(n_estimators=500, learning_rate=0.5,max_depth=6,random_state=0,n_jobs=-1)\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate model for each Store\n",
    "pred3=np.zeros(test_val.shape[0])\n",
    "\n",
    "train_store = train2.groupby(['Store'])\n",
    "test_store = test_val2.groupby(['Store'])\n",
    "\n",
    "for i in range(1,1116):\n",
    "    a = train_store.get_group(i)\n",
    "    b = test_store.get_group(i)\n",
    "    X_train = a.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    X_val = b.drop(['Sales','Date','Store','Customers','Open'],axis=1).values\n",
    "    Y_train = a['Sales']\n",
    "    clf = XGBRegressor(n_estimators=500, learning_rate=0.5,max_depth=6,random_state=0,n_jobs=-1)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    pred = clf.predict(X_val)\n",
    "    i=0\n",
    "    ind=b[b['Open']==0].index\n",
    "    for j in b.index:\n",
    "        if(j in ind):\n",
    "            pred3[j]=0\n",
    "        else:\n",
    "            pred3[j]=pred[i]\n",
    "        i+=1\n",
    "print('MSE',np.sqrt(mean_squared_error(pred3,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred3,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "Y_train = train1['Sales']\n",
    "Y_val = test_val1['Sales']\n",
    "pca = PCA(n_components=50) \n",
    "X_train = pca.fit_transform(X_train)  \n",
    "X_val= pca.transform(X_val) \n",
    "\n",
    "clf = XGBRegressor(n_estimators=500, learning_rate=0.1,max_depth=6,random_state=0,n_jobs=-1,objective='reg:linear', \n",
    "                   booster='gbtree')\n",
    "clf.fit(X_train,Y_train)\n",
    "pred1 = clf.predict(X_val)\n",
    "\n",
    "ind=test_val[test_val.Open==0].index\n",
    "for i in ind:\n",
    "    pred1[i] = 0\n",
    "    \n",
    "print('MSE',np.sqrt(mean_squared_error(pred1,Y_val)))\n",
    "print('MAE',mean_absolute_error(pred1,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\n",
    "Train = pd.read_csv(\"train_data.csv\", parse_dates=['Date'], index_col='Date',date_parser=dateparse)\n",
    "Test_val = pd.read_csv(\"test_data_hidden.csv\", parse_dates=['Date'], index_col='Date',date_parser=dateparse)\n",
    "Train=Train[['Store','Sales','Open','DayOfWeek']]\n",
    "Test_val=Test_val[['Store','Sales','Open','DayOfWeek']]\n",
    "print ('\\n Parsed Data:')\n",
    "Train.sort_values(['Date'],axis=0,inplace=True)\n",
    "Test_val.sort_values(['Date'],axis=0,inplace=True)\n",
    "print (Train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store1=Train[Train.Store==1]\n",
    "test_store1=Test_val[Test_val.Store==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"DayOfWeek\", y=\"Sales\", data=store1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday=1, Sunday=7.\n",
    "\n",
    "Here we can find on Sunday stores are closed. Monday has little larger sales, Thurdays has little smaller. There's a few outliers on all days(except Sunday) but it is less on Weekdays(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(store1['Sales'], model='additive',freq=365)\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(12).mean()\n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_stationarity(store1['Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller p-value, the more likely it's stationary. Here our p-value is 0.000415. It's actually good, but as we just visually found a little downward trend, we want to be more strict, i.e. if the p value further decreases, this series would be  more likely to be stationary.\n",
    "To get a stationary data, there's many techiniques. We can use log, differencing etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_diff = store1['Sales'] - store1['Sales'].shift(1)\n",
    "first_diff = first_diff.dropna(inplace = False)\n",
    "test_stationarity(first_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After differencing, the p-value is extremely small. Thus this series is very likely to be stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#AR model\n",
    "ar_mod = ARIMA(store1.Sales, (9,1,0),freq='D')\n",
    "res=ar_mod.fit(disp=False)\n",
    "Y_pred = res.forecast(steps=31)[0]\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred,test_store1.Sales)))\n",
    "print('MAE',mean_absolute_error(Y_pred,test_store1.Sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MA model\n",
    "ma_mod = ARIMA(store1.Sales, (0,1,1),freq='D')\n",
    "res=ma_mod.fit(disp=False)\n",
    "Y_pred = res.forecast(steps=31)[0]\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred,test_store1.Sales)))\n",
    "print('MAE',mean_absolute_error(Y_pred,test_store1.Sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ARIMA model\n",
    "arima_mod = ARIMA(store1.Sales, (9,1,9),freq='D')\n",
    "res=arima_mod.fit(disp=False)\n",
    "Y_pred = res.forecast(steps=31)[0]\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred,test_store1.Sales)))\n",
    "print('MAE',mean_absolute_error(Y_pred,test_store1.Sales))\n",
    "store1['pred']=Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 3\n",
    "\n",
    "#### Implementing Neural Networks:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM for store1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store1 = store1.iloc[:, 1:2].values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "train_store1 = sc.fit_transform(train_store1)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(30, 911):\n",
    "    X_train.append(train_store1[i-30:i, 0])\n",
    "    Y_train.append(train_store1[i, 0])\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 30, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(LSTM(units = 70, return_sequences = True))\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "regressor.fit(X_train, Y_train, epochs = 100, batch_size = 64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat((store1['Sales'], test_store1['Sales']), axis = 0)\n",
    "inputs = total_data[len(total_data) - len(test_store1) - 30:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(30, 61):\n",
    "    X_test.append(inputs[i-30:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "pred = regressor.predict(X_test)\n",
    "pred= sc.inverse_transform(pred)\n",
    "print(np.sqrt(mean_squared_error(pred,test_store1.Sales)))\n",
    "print(mean_absolute_error(pred,test_store1.Sales)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(test_store1.Sales, color = 'red', label = 'Actual Sales')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted Sales')\n",
    "plt.title('Sales Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sale')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying ANN:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model1\n",
    "X_train = train2.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val = test_val2.drop(['Sales','Date','Customers'],axis=1).values\n",
    "Y_train = pd.DataFrame(train2['Sales'])\n",
    "Y_val = test_val2['Sales']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "Y_train = sc.fit_transform(Y_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim = X_train.shape[1]))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear',kernel_initializer='normal') )\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=64,shuffle=False,verbose=0)\n",
    "Y_pred = model.predict(X_val, batch_size=64,verbose=0)\n",
    "Y_pred= sc.inverse_transform(Y_pred)\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred,Y_val))\n",
    "# MSE 2515.353601819651\n",
    "#MAE 1676.8835278851793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model2\n",
    "X_train = train1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "X_val = test_val1.drop(['Sales','Date','Customers'],axis=1).values\n",
    "Y_train = pd.DataFrame(train1['Sales'])\n",
    "Y_val = test_val1['Sales']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "Y_train = sc.fit_transform(Y_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim = X_train.shape[1]))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear') )\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=64,shuffle=False,verbose=0)\n",
    "Y_pred = model.predict(X_val, batch_size=64,verbose=0)\n",
    "Y_pred= sc.inverse_transform(Y_pred)\n",
    "\n",
    "\n",
    "print('MSE',np.sqrt(mean_squared_error(Y_pred,Y_val)))\n",
    "print('MAE',mean_absolute_error(Y_pred,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
